# **What is Word2Vec?**

Word2vec is a technique for natural language processing (NLP) published in 2013. The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence.

## ARCHITECHTURE OF Word2Vec:

These models are shallow *two-layer neural networks* having one input layer, one hidden layer, and one output layer. Word2Vec utilizes two architectures :

**CBOW (Continuous Bag of Words)** : CBOW model predicts the current word given context words within a specific window.

**Skip Gram** : Skip gram predicts the surrounding context words
 within specific window given current word.

RESOURCES:

YOUTUBE LINK:

[Word2Vec-Data Science](https://youtu.be/Otde6VGvhWM)

[A simple explanation- word2vec](https://youtu.be/hQwFeIupNP0)

[Programming With Text-Word2Vec](https://youtu.be/LSS_bos_TPI)

BLOG LINK:

[READ A BLOG!!!](https://towardsdatascience.com/word2vec-explained-49c52b4ccb71)

