# What is Adversarial Regularization?
This generalisation of NSL is known as Adversarial Regularisation, where adversarial examples are constructed to intentionally confuse the model during training, resulting in models that are robust against small input perturbations.

![](<https://miro.medium.com/v2/resize:fit:968/1*AuC-ZlRwuV3-obQj0Pk1uA.png>)


### Reference:

- [TowardsDataScience](https://towardsdatascience.com/neural-structured-learning-adversarial-regularization-378523dace08)
- [TensorFlow](https://www.tensorflow.org/neural_structured_learning/tutorials/adversarial_keras_cnn_mnist)
- [Youtube](https://www.youtube.com/watch?v=Js2WJkhdU7k)

