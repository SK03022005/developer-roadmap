# Adversarial Reinforcement Learning
Adversarial Reinforcement Learning (ARL) is a subfield of Reinforcement Learning (RL) that involves multiple agents, where each agent seeks to maximize its own reward function in a competitive environment. In ARL, agents learn by interacting with each other, and the goal is to develop robust strategies that can perform well in the presence of other agents who may be actively trying to interfere with their success.
## Resources
- [Adversarial machine learning](https://en.wikipedia.org/wiki/Adversarial_machine_learning)
- [Reinventing Adversarial Machine Learning](https://towardsdatascience.com/reinventing-adversarial-machine-learning-adversarial-ml-from-scratch-c5330595ade0)
- [Adversarial Robustness Toolbox](https://adversarial-robustness-toolbox.readthedocs.io/en/latest/)
- [Adversarial Policies: Attacking Deep Reinforcement Learning](https://www.youtube.com/watch?v=-_j-fmVpn_s)
- [Adversarial Attacks and Defenses in Reinforcement Learning](https://www.youtube.com/watch?v=j1Img72wp00)